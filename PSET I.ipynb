{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from siftdetector import detect_keypoints\n",
    "%matplotlib inline\n",
    "from numpy_sift import SIFTDescriptor \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/dev/opencv-3.1/build/lib')\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from math import log\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_labels(directoryList, range_size, added_limit, count_limit, patch_size=32):\n",
    "    SD = SIFTDescriptor(patchSize = patch_size)\n",
    "\n",
    "    #creates initial vector of size 3968\n",
    "    sift_pictures = np.asarray([[0 for _ in range(range_size)]])\n",
    "    for directory in directoryList:\n",
    "        #go through the directories with the relevant images\n",
    "        for filename in os.listdir(directory):\n",
    "            name = directory + '/' + filename\n",
    "            print name\n",
    "            if name[-3:] == 'png' or name[-3:] == 'jpg':\n",
    "                image = cv2.imread(name)\n",
    "                \n",
    "                #transform it to black and white and get features\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                h, w = gray.shape\n",
    "                corners = cv2.goodFeaturesToTrack(gray,count_limit,0.001,10)\n",
    "\n",
    "                corners = np.int0(corners)\n",
    "                image_sift_features = np.asarray([]) \n",
    "                count, actually_added = 0, 0\n",
    "                \n",
    "                #Here we want to get 31 images for our feature vector and then break out of the loop\n",
    "                while actually_added < added_limit and count < count_limit:\n",
    "                    corner = corners[count][0]\n",
    "                    if patch_size/2 <= corner[1] <= h-patch_size/2 and patch_size/2 <= corner[0] <= w-patch_size/2:\n",
    "                        patch = gray[corner[1]-patch_size/2:corner[1]+patch_size/2, corner[0]-patch_size/2:corner[0]+patch_size/2]\n",
    "                        sift = SD.describe(patch)\n",
    "                        image_sift_features = np.append(image_sift_features, sift)\n",
    "                        actually_added += 1\n",
    "                    count += 1\n",
    "\n",
    "                sift_pictures = np.append(sift_pictures, [image_sift_features], axis=0)\n",
    "\n",
    "    return sift_pictures[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auditorium/.DS_Store\n",
      "Auditorium/00000001.jpg\n",
      "Auditorium/00000003.jpg\n",
      "Auditorium/00000004.jpg\n",
      "Auditorium/00000008.jpg\n",
      "Auditorium/00000009.jpg\n",
      "Auditorium/00000011.jpg\n",
      "Auditorium/00000016.jpg\n",
      "Auditorium/00000022.jpg\n",
      "Auditorium/00000024.jpg\n",
      "Auditorium/00000025.jpg\n",
      "Auditorium/00000026.jpg\n",
      "Auditorium/00000030.jpg\n",
      "Auditorium/00000031.jpg\n",
      "Auditorium/00000032.jpg\n",
      "Auditorium/00000049.jpg\n",
      "Auditorium/00000062.jpg\n",
      "Bowling/.DS_Store\n",
      "Bowling/00000006.jpg\n",
      "Bowling/00000010(1).jpg\n",
      "Bowling/00000011.jpg\n",
      "Bowling/00000012(1).jpg\n",
      "Bowling/00000026(1).jpg\n",
      "Bowling/00000029(1).jpg\n",
      "Bowling/00000031.jpg\n",
      "Bowling/00000044.jpg\n",
      "Bowling/00000055(1).jpg\n",
      "Bowling/00000058.jpg\n",
      "Bowling/00000059.jpg\n",
      "Bowling/00000072.jpg\n",
      "Bowling/00000095.jpg\n",
      "Bowling/00000098.jpg\n",
      "Bowling/00000104.jpg\n",
      "Bowling/00000126(1).jpg\n",
      "Bowling/00000129(1).jpg\n",
      "Bowling/00000134(1).jpg\n",
      "test/.DS_Store\n",
      "test/00000002.jpg\n",
      "test/00000017.jpg\n",
      "test/00000162.jpg\n",
      "test/00000190.jpg\n",
      "test/00000510.jpg\n",
      "test/00000591.jpg\n",
      "[1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 3968 features, expected 2304",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-33ebe77c5c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_pictures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3968\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msift_pictures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pictures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_centers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/sklearn/cluster/k_means_.pyc\u001b[0m in \u001b[0;36m_check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    869\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[1;32m    870\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[0;32m--> 871\u001b[0;31m                                  n_features, expected_n_features))\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features. Got 3968 features, expected 2304"
     ]
    }
   ],
   "source": [
    "sift_pictures = return_labels(['Auditorium', 'Bowling'], 2304, 18, 100)\n",
    "kmeans = KMeans(n_clusters=2, random_state=1).fit(sift_pictures)\n",
    "test_pictures = return_labels(['test'], 3968, 31, 100)\n",
    "print kmeans.predict(sift_pictures)\n",
    "print kmeans.predict(test_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
